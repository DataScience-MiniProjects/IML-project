---
title: "Project Challenge"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Used libraries
```{r, message=F}
library(ggfortify)
library(randomForest)
library(caret)
```

Read data

```{r}
#setwd("path/to/folder")
set.seed(42)

npf <- read.csv("npf_train.csv")
npf_test <- read.csv("npf_test_hidden.csv")

rownames(npf) <- npf[,"date"]

#npf <- npf[,c(-1,-4)]
#npf_test <- npf_test[,c(-1,-4)]


# npf <- npf[, c("date",	"class4", "CO242.mean",	"CO2504.mean",	"Glob.mean",	
#                 "H2O42.mean",	"H2O504.mean", "NET.mean",	"NO42.mean",	"NO504.mean",	
#                 "NOx42.mean",	"NOx504.mean", "O342.mean",	"O3504.mean",	"Pamb0.mean",	
#                 "PAR.mean",	"PTG.mean", "RGlob.mean",	"RHIRGA42.mean",	"RHIRGA504.mean",	
#                 "RPAR.mean", "SO2168.mean",	"SWS.mean",	"T42.mean",	"T504.mean",	"UV_A.mean",	
#                 "CS.mean")]
# 
# npf_test <- npf_test[, c("CO242.mean",	"CO2504.mean",	"Glob.mean",	
#                 "H2O42.mean",	"H2O504.mean", "NET.mean",	"NO42.mean",	"NO504.mean",	
#                 "NOx42.mean",	"NOx504.mean", "O342.mean",	"O3504.mean",	"Pamb0.mean",	
#                 "PAR.mean",	"PTG.mean", "RGlob.mean",	"RHIRGA42.mean",	"RHIRGA504.mean",	
#                 "RPAR.mean", "SO2168.mean",	"SWS.mean",	"T42.mean",	"T504.mean",	"UV_A.mean",	
#                 "CS.mean")]
vars <- colnames(npf)[sapply(colnames(npf),
                             function(s) nchar(s)>5 && substr(s,nchar(s)-4,nchar(s))==".mean")]
vars2 <- colnames(npf_test)[sapply(colnames(npf_test),
                             function(s) nchar(s)>5 && substr(s,nchar(s)-4,nchar(s))==".mean")]
npf <- npf[,c(vars,"class4")]
npf_test <- npf_test[,c(vars2)]
## strip the trailing ".mean" to make the variable names prettier
colnames(npf)[1:length(vars)] <- sapply(colnames(npf)[1:length(vars)],
                                        function(s) substr(s,1,nchar(s)-5))
vars <- colnames(npf)[1:length(vars)]

colnames(npf_test)[1:length(vars2)] <- sapply(colnames(npf_test)[1:length(vars2)],
                                        function(s) substr(s,1,nchar(s)-5))
vars2 <- colnames(npf_test)[1:length(vars2)]
#npfBin <- npf
#npfBin$class2 <- factor("event",levels=c("nonevent","event"))
#npfBin$class2[npf$class4=="nonevent"] <- "nonevent"
#npf <- npf[,-1]
#npfBin <- npfBin[,-1]
#npfBin <- subset(npfBin, select=-c(class4))
```

```{r}
# vars <- c("CO242.mean",	"CO2504.mean",	"Glob.mean",	
#                 "H2O42.mean",	"H2O504.mean", "NET.mean",	"NO42.mean",	"NO504.mean",	
#                 "NOx42.mean",	"NOx504.mean", "O342.mean",	"O3504.mean",	"Pamb0.mean",	
#                 "PAR.mean",	"PTG.mean", "RGlob.mean",	"RHIRGA42.mean",	"RHIRGA504.mean",	
#                 "RPAR.mean", "SO2168.mean",	"SWS.mean",	"T42.mean",	"T504.mean",	"UV_A.mean",	
#                 "CS.mean")
npf.pcA2 <- prcomp(scale(npf[,vars]))
npf.pcA2.withtest <- prcomp(scale(rbind(npf[,vars],npf_test[,vars])))
autoplot(npf.pcA2, data=npf, colour="class4", loadings=T, loadings.label=T)
```


Binary accuracy on random forest classifier with different sized training/validation sets:
## Binary accuracy (class 2)


## Accuracy of the estimate of accuracy

```{r}

```

## Perplexity

```{r}

```

## Multi-class accuracy (class4)

Multiclass accuracy on the random forest classifier:

```{r}
set.seed(42)
# Calculates the accuracy to each class and the total accuracy
accClass4 <-function(p,dataset) {
  true_vals <- 0;ia <- 0;ib <- 0;
  ii <- 0;nonevent <- 0;
  for (i in 1:length(dataset$class4)) {
    if (p$Ia[i] > p$nonevent[i] & p$Ia[i] > p$II[i] &
        p$Ia[i] > p$Ib[i] & dataset$class4[i]=="Ia") {
      true_vals<-true_vals+1;ia<-ia+1;
    }
    if (p$Ib[i] > p$nonevent[i] & p$Ib[i] > p$II[i] &
        p$Ib[i] > p$Ia[i] & dataset$class4[i]=="Ib") {
      true_vals<-true_vals+1;ib <- ib + 1;
    }
    if (p$II[i] > p$nonevent[i] & p$II[i] > p$Ia[i] &
        p$II[i] > p$Ib[i] & dataset$class4[i]=="II") {
      true_vals<-true_vals+1;ii<-ii+1;
    }
    if (p$nonevent[i] > p$II[i] & p$nonevent[i] > p$Ia[i] &
        p$nonevent[i] > p$Ib[i] & dataset$class4[i]=="nonevent") {
      true_vals<-true_vals+1;nonevent<-nonevent+1;
    }
  }
  return(c(true_vals/length(dataset$class4), 
         ia/length(which(dataset$class4=="Ia")),
         ib/length(which(dataset$class4=="Ib")), 
         ii/length(which(dataset$class4=="II")), 
         nonevent/length(which(dataset$class4=="nonevent"))))
}
npf.pcA2 <- prcomp(npf[,vars], center=T, scale=T)
nmbr = c(90, 180, 270)
accuracy_4 <-data.frame("Total","Ia","Ib","II","Nonevent")

for (i in 1:3) {
  idx <- sample.int(nrow(npf),nmbr[i])
  training_set <- npf[ idx,]
  validation_set <- npf[-idx,]
  train.pc <- data.frame(npf.pcA2$x[idx,1:14])
  train.pc$class4 <- npf[idx,]$class4
  validate.pc <- data.frame(npf.pcA2$x[-idx,1:14])
  validate.pc$class4 <- npf[-idx,]$class4
  ctrl <- trainControl(method = "repeatedcv",
                       number = 10,
                       repeats = 10,
                       classProbs = TRUE)
  rFClass4 <- train(factor(class4) ~ .,
                      method="rf",
                      data=train.pc,
                      trControl=ctrl)
  probs4 <- predict(rFClass4, newdata = validate.pc, type = "prob")
  accuracy_4 <- rbind(accuracy_4, accClass4(probs4, validation_set))
  pred <- predict(rFClass4, newdata = validate.pc)
  confusionMatrix(pred, factor(validate.pc$class4))
}
accuracy_4
```


```{r}
train.pc <- data.frame(npf.pcA2.withtest$x[1:458,1:14])
train.pc$class4 <- npf$class4

test.pc <- data.frame(npf.pcA2.withtest$x[459:(458+nrow(npf_test)),1:14])

ctrl <- trainControl(method = "repeatedcv",
                     number = 10,
                     repeats = 10,
                     classProbs = TRUE)
rFClass4 <- train(factor(class4) ~ .,
                    method="rf",
                    data=train.pc,
                    trControl=ctrl)

pred_test4 <- predict(rFClass4, newdata = test.pc)
probs_test4 <- predict(rFClass4, newdata = test.pc, type = "prob")

length(which(pred_test4=="nonevent"))
length(which(pred_test4=="Ia"))
length(which(pred_test4=="Ib"))
length(which(pred_test4=="II"))
```

```{r}
# Code to produce the answer-csv
# The first column "class4" in the answers.csv file is our 
# prediction for the day, where class4 is Ia, Ib, II, or nonevent.
# The second column "p" is our prediction for probability Pr(class2=event)


# Creates the csv and adds the first line
# Change the string here to our guess of the accuracy
write.table(0.75,
             file="./answers.csv",
             append = F,
             sep=',',
             row.names=F,
             col.names=F)

# Write column names to the file
write.table(data.frame("class4","p"),
            file="./answers.csv",
            append = T,
            sep=',',
            row.names=F,
            col.names=F)

# testing testing
#setwd()
#probs_test4 <- data.frame(c(0.1,0.2,0.5,0.1,0.5),c(0.6,0.05,0.1,0.2,0.05),c(0.1,0.7,0.2,0.2,0.15),c(0.2,0.05,0.2,0.5,0.3))
#colnames(probs_test4)<- c("Ia","Ib","II","nonevent")

# Assume the class probabilities for each row are in probs_test4
classes_test4 <- colnames(probs_test4)[max.col(probs_test4, ties.method = "first")]

# Write the class predictions and probabilities
write.table(data.frame(classes_test4, (probs_test4$Ia+probs_test4$Ib+probs_test4$II)),
            file="./answers.csv",
            append = T,
            sep=',',
            row.names=F,
            col.names=F)

```

